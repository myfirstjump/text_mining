{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出\n",
    "IDF\n",
    "\n",
    "TFIDF\n",
    "\n",
    "keywords dictionary\n",
    "\n",
    "keywords sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Java\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.596 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Java\\\\Desktop\\\\TM\\\\IDF\\\\100-weight-allTags-Titlize_allIDF0927.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d70ac1306c29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;31m#read idf files (a dictionary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;31m#f = open(filePath + \"\\\\IDF\\\\{}kw-{}-weight-{}-{}IDF{}.txt\".format(15, multi, focus, str(src), nowtime), 'r', encoding='utf-8')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilePath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\\\IDF\\\\{}-weight-{}-{}IDF{}.txt\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmulti\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfocus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnowtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[0m_idf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Java\\\\Desktop\\\\TM\\\\IDF\\\\100-weight-allTags-Titlize_allIDF0927.txt'"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import jieba\n",
    "import math\n",
    "import operator\n",
    "import json\n",
    "import jieba.analyse\n",
    "import time\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "version = 1 #\n",
    "startT = time.time()\n",
    "src = \"Titlize_all\" # DB 讀取來源 collection\n",
    "filePath = \"C:\\\\Users\\\\Java\\\\Desktop\\\\TM\"\n",
    "focus = \"allTags\" # 欲加強的目標\n",
    "multi = 100  # 加強目標的權重\n",
    "nowtime = \"0927\"#time.strftime(\"%m%d\")\n",
    "kwNum = 5\n",
    "\n",
    "# \"Kyoto_Titlize\"\n",
    "# \"渡月橋\" Togetsukyō\n",
    "# \"平等院鳳凰堂\"  Byōdōin\n",
    "# \"千本鳥居\" Fushimi-Inari Taisha\n",
    "# \"京都御所\" Kyōto gosho\n",
    "# \"京都塔\" kyoto tower\n",
    "# \"二條城\" Nijō-jō\n",
    "# \"三十三間堂\" Sanjūsangen-dō\n",
    "# \"清水寺\" Kiyomizu-dera\n",
    "# \"金閣寺\" Rokuonji\n",
    "\n",
    "# focus list:\n",
    "# TAGactivity.txt\n",
    "# TAGsite.txt\n",
    "# TAGrestaurant.txt\n",
    "# TAGshopping.txt\n",
    "# TAGwearing.txt\n",
    "\n",
    "# user dict\n",
    "\n",
    "# jieba.load_userdict(filePath + \"\\\\TEST.txt\")\n",
    "jieba.load_userdict(filePath + \"\\\\userDict\\\\dict.txt\") # taiba字典\n",
    "jieba.load_userdict(filePath + \"\\\\userDict\\\\hotel.txt\")\n",
    "jieba.load_userdict(filePath + \"\\\\userDict\\\\people.txt\")\n",
    "jieba.load_userdict(filePath + \"\\\\userDict\\\\stopwords.txt\") # stopwords先當作字典讓 jieba 切出來，之後再排除\n",
    "jieba.load_userdict(filePath + \"\\\\userDict\\\\京都市町名.txt\")\n",
    "jieba.load_userdict(filePath + \"\\\\userDict\\\\京都駅名.txt\")\n",
    "\n",
    "jieba.load_userdict(filePath + \"\\\\userDict\\\\tags\\\\TAGactivity.txt\")\n",
    "jieba.load_userdict(filePath + \"\\\\userDict\\\\tags\\\\TAGsite.txt\")\n",
    "jieba.load_userdict(filePath + \"\\\\userDict\\\\tags\\\\TAGrestaurant.txt\")\n",
    "jieba.load_userdict(filePath + \"\\\\userDict\\\\tags\\\\TAGshopping.txt\")\n",
    "jieba.load_userdict(filePath + \"\\\\userDict\\\\tags\\\\TAGwearing.txt\")\n",
    "\n",
    "# stop dict\n",
    "\n",
    "# 載入focus\n",
    "g = open(filePath + \"\\\\userDict\\\\tags\\\\{}.txt\".format(focus), 'r', encoding='utf-8')\n",
    "focused = g.readlines()\n",
    "site = []\n",
    "# cnt=0\n",
    "for item in focused:\n",
    "    site.append(item.strip())\n",
    "g.close()\n",
    "\n",
    "# stop dict\n",
    "f = open(filePath + \"\\\\userDict\\\\stopwords.txt\", 'r', encoding='utf-8')\n",
    "stopwords = f.readlines()\n",
    "ignore = []\n",
    "# cnt=0\n",
    "for item in stopwords:\n",
    "    ignore.append(item.strip())\n",
    "f.close()\n",
    "\n",
    "# read data\n",
    "conn = MongoClient('127.0.0.1', 27017)  ##連 Mongodb\n",
    "db = conn.text_mining  ##創造DB  改程式碼的時候注意一下 這行的DB也要改\n",
    "db.authenticate('text_mining', 'bb102', source='text_mining')  # text_mining帳號 #bb102密碼 #test123允許儲存的db\n",
    "collection = db[src]  ##創造collection\n",
    "articleList = []\n",
    "for item in collection.find({}, {\"內文\": 1, \"_id\": 0}):  # for others\n",
    "    if item != {}:\n",
    "        articleList.append(item)\n",
    "\n",
    "articles = []\n",
    "for atc in articleList:\n",
    "    article1 = atc.get('內文') #.split(\"※ 發信站\")[0].lower()\n",
    "    #article2 = \"\".join([i for i in filter(lambda ch: ch not in ignore, article1)])  # 去掉數字和特殊符號              \n",
    "    articles.append(article1.replace(\" \",\"\").replace(\"　\", \"\").replace(u'\\u200b', ''))\n",
    "\n",
    "urls = []\n",
    "for item in collection.find({}, {\"url\": 1, \"_id\": 0}):  # for others\n",
    "    if item != {}:\n",
    "        urls.append(item)\n",
    "        \n",
    "titles = []\n",
    "for item in collection.find({}, {\"標題\": 1, \"_id\": 0}):  # for others\n",
    "    if item != {}:\n",
    "        titles.append(item)\n",
    "\n",
    "dbReadT = time.time()\n",
    "        \n",
    "# # article string -> term freq (tf)\n",
    "\n",
    "def atc2tf(article):\n",
    "    cut_line = jieba.cut(article)\n",
    "    cnt = 0\n",
    "    tf_dict = {}\n",
    "    for word in cut_line:\n",
    "        cnt = cnt + 1\n",
    "        if word not in ignore: # 篩選 by 自定義的 stop words\n",
    "            #print(\"key: \" + str(word))# + \"value:\" + str(tf_dict.get(word)))\n",
    "            if word in site:\n",
    "                if word in tf_dict:\n",
    "                    tf_dict[word] += 1*multi\n",
    "                else:\n",
    "                    tf_dict[word] = 1*multi\n",
    "            else:\n",
    "                if word in tf_dict:\n",
    "                    tf_dict[word] += 1\n",
    "                else:\n",
    "                    tf_dict[word] = 1\n",
    "    for word in tf_dict:\n",
    "        #print(\"key: \" + str(word) + \"value:\" + str(tf_dict.get(word)))\n",
    "        tf_dict[word] = tf_dict.get(word)/cnt\n",
    "    return tf_dict\n",
    "\n",
    "# articles -> inverse document freq (idf)\n",
    "\n",
    "def atcs2idf(articles):\n",
    "    idf_dict = {}\n",
    "    all_dict = {}\n",
    "    total = 0\n",
    "    for article in articles:\n",
    "        total += 1\n",
    "        tmp_dict = {}\n",
    "        cut_line = jieba.cut(article)\n",
    "        for word in cut_line:\n",
    "            if word in ignore:\n",
    "                continue\n",
    "            tmp_dict[word] = 1\n",
    "        for key in tmp_dict:\n",
    "            num = all_dict.get(key, 0)  # 用key搜尋value，0是此key不存在時的回傳值\n",
    "            all_dict[key] = num + 1\n",
    "    for key in all_dict:\n",
    "        p = math.log10(total/(all_dict[key]))\n",
    "        idf_dict[key] = p\n",
    "    return idf_dict\n",
    "\n",
    "# atcs2idf + atc2tf -> atc_tfidf\n",
    "\n",
    "def atc2tfidf(article, idf):\n",
    "    tfidf_dict = {}\n",
    "    tf = atc2tf(article)\n",
    "    for word in tf:\n",
    "        tfidf_dict[word] = tf[word] * idf[word]\n",
    "    return tfidf_dict\n",
    "\n",
    "\n",
    "#read idf files (a dictionary)\n",
    "#f = open(filePath + \"\\\\IDF\\\\{}kw-{}-weight-{}-{}IDF{}.txt\".format(15, multi, focus, str(src), nowtime), 'r', encoding='utf-8')\n",
    "f = open(filePath + \"\\\\IDF\\\\{}-weight-{}-{}-IDF{}.txt\".format( multi, focus, str(src), nowtime), 'r', encoding='utf-8')\n",
    "_idf = json.loads(f.read())\n",
    "f.close()\n",
    "\n",
    "# 用 atcs2idf function 建立 idf 文件 dictionary\n",
    "# _idf = atcs2idf(articles)\n",
    "\n",
    "idfT = time.time()\n",
    "\n",
    "# 將建立好的 idf 儲存為 txt\n",
    "# if os.path.exists(filePath + \"\\\\IDF\\\\\") == False:\n",
    "#     os.makedirs(filePath + \"\\\\IDF\\\\\")\n",
    "# f = open(filePath + \"\\\\IDF\\\\{}kw-{}-weight-{}-{}IDF{}.txt\".format(kwNum, multi, focus, str(src), nowtime), 'w', encoding='utf-8')\n",
    "# x = json.dumps(_idf, ensure_ascii = False)\n",
    "# f.write(x)\n",
    "# f.close()\n",
    "\n",
    "idfSaveT = time.time()\n",
    "\n",
    "## 輸出 df-idf\n",
    "# if os.path.exists(filePath + \"\\\\TFIDF\\\\\") == False:\n",
    "#     os.makedirs(filePath + \"\\\\TFIDF\\\\\")\n",
    "# with open(filePath + \"\\\\TFIDF\\\\{}kw-{}-weight-{}-{}TFIDF{}.txt\".format(kwNum, multi, focus, str(src), nowtime), 'w', encoding='utf-8') as f:\n",
    "#     for i in range(0, len(articles)):\n",
    "#         try:\n",
    "#             x = atc2tfidf(articles[i], _idf)\n",
    "#             sorted_x = sorted(x.items(), key=operator.itemgetter(1), reverse = True)\n",
    "#             f.write(\"== {} ==\\n\".format(i))\n",
    "#             f.write(str(urls[i]['url'])+\"\\n\")\n",
    "#             for j in range(0,5):\n",
    "#                 f.write(str(sorted_x[j][0])+\"\\n\")\n",
    "#         except IndexError as e:\n",
    "#             print(e); pass\n",
    "\n",
    "tfidfSaveT = time.time()\n",
    "        \n",
    "    \n",
    "print(\"dbRead & filtering: {}\".format(dbReadT - startT))\n",
    "print(\"idf build         : {}\".format(idfT - dbReadT))\n",
    "print(\"idf Save          : {}\".format(idfSaveT - idfT))\n",
    "print(\"tf-idf build      : {}\".format(tfidfSaveT - idfSaveT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls[628]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\" / \".join(jieba.cut(articles[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  篩選標題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## db.getCollection('平等院鳳凰堂_Titlize').find({\"標題\":{\"$regex\":\"問題\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cato = {}\n",
    "# for i in titles:\n",
    "#     x = \"\".join(re.findall(\"^\\[(..)\\]\", i['標題']))\n",
    "#     if x not in cato:\n",
    "#         cato[x] = 1\n",
    "#     else:\n",
    "#         cato[x] += 1\n",
    "# cato.pop(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sorted(cato.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### [問題] Question = []\n",
    "# cnt = 0\n",
    "# Question = []\n",
    "# for i in titles:\n",
    "#     x = re.findall(\"\\[問題]\", i['標題']) \n",
    "#     if x == ['[問題]']:\n",
    "#         Question.append(cnt)\n",
    "#     cnt += 1\n",
    "# # for i in titles:\n",
    "# #     print(i['標題'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### [徵文] Election = []\n",
    "# cnt = 0\n",
    "# Election = []\n",
    "# for i in titles:\n",
    "#     x = re.findall(\"\\[徵文]\", i['標題']) \n",
    "#     if x == ['[徵文]']:\n",
    "#         Election.append(cnt)\n",
    "#     cnt += 1\n",
    "# # for i in titles:\n",
    "# #     print(i['標題'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 生成 kwNum 個 keywords for each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 每篇keywords生成一筆dictionary\n",
    "##### 內涵 url & keywords\n",
    "kBuildStart = time.time()\n",
    "keywords = []\n",
    "for i in range(0, len(articles)):\n",
    "    kwd = {}\n",
    "    try:\n",
    "        x = atc2tfidf(articles[i], _idf)\n",
    "        sorted_x = sorted(x.items(), key=operator.itemgetter(1), reverse = True)\n",
    "        for j in range(0, kwNum):\n",
    "            kwd[str(sorted_x[j][0])] = str(sorted_x[j][1])\n",
    "        kwd['url'] = urls[i].get('url', 0)   # url\n",
    "        kwd['title'] = titles[i].get('標題', 0)    # title\n",
    "        keywords.append(kwd)     \n",
    "    except IndexError as e:\n",
    "        kwd['url'] = urls[i].get('url', 0)     # url\n",
    "        kwd['title'] = titles[i].get('標題', 0)    # title\n",
    "        keywords.append(kwd)     # url\n",
    "        pass\n",
    "kBuildDone = time.time()\n",
    "print(\"keywords build : {}\".format(kBuildDone-kBuildStart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Save\n",
    "keywords dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # 儲存 keywords\n",
    "# kSaveStart = time.time()\n",
    "# f = open(filePath + \"\\\\clustering\\\\keywordsSets\\\\{}kw-{}-weight-{}-{}keywords{}.txt\".format(kwNum, multi, focus, str(src), nowtime), 'w', encoding=\"utf-8\")\n",
    "# f.write(json.dumps(keywords, ensure_ascii = False))\n",
    "# f.close()\n",
    "# kSaveDone = time.time()\n",
    "# print(\"keywords Save : {}\".format(kSaveDone-kSaveStart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "keywords set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 關鍵詞塞入 set 並存成txt\n",
    "\n",
    "# distinct_kw = set()\n",
    "# for item in keywords:\n",
    "#     x = item.keys()\n",
    "#     for i in x:\n",
    "#         distinct_kw.add(i)\n",
    "# kSetBuildStart = time.time()  \n",
    "# f = open(filePath + \"\\\\clustering\\\\keywordsSets\\\\{}kw-{}-weight-{}-{}kwSet{}.txt\".format(kwNum, multi, focus, str(src), nowtime), 'w', encoding=\"utf-8\")\n",
    "# for i in distinct_kw:\n",
    "#     f.write(i+\"\\n\")\n",
    "# f.close()\n",
    "# kSetBuildDone = time.time()\n",
    "# print(\"keywords set build : {}\".format(kSetBuildDone-kSetBuildStart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成 fp growth 所需格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g = open(\"C:\\\\Users\\\\Java\\\\Desktop\\\\TM\\\\Association\\\\fpgData{}.txt\".format(nowtime), 'w', encoding='utf-8')\n",
    "\n",
    "# for i in range(0, len(keywords)):\n",
    "#     line = \" \".join([j for j in keywords[i]])\n",
    "#     g.write(line + \"\\n\")    \n",
    "# g.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
